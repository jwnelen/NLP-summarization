{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3c0bfcc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/NLP-summarization/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Reusing dataset cnn_dailymail (/Users/jeroen/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234)\n",
      "100%|████████████████████████████████████████████| 3/3 [00:00<00:00, 161.67it/s]\n",
      "No model was supplied, defaulted to t5-small (https://huggingface.co/t5-small)\n",
      "2022-04-01 16:46:45.371865: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at t5-small.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "from transformers import pipeline\n",
    "\n",
    "raw_dataset = load_dataset('cnn_dailymail', '3.0.0')\n",
    "\n",
    "classifier = pipeline(\"summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32506305",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_examples(dataset, num_samples=3, seed=42):\n",
    "    samples = dataset[\"train\"].shuffle(seed=seed).select(range(num_samples))\n",
    "        \n",
    "    for idx, sample in enumerate(samples):\n",
    "        display(f'sample {idx}: {sample[\"article\"]} \\n')\n",
    "        display(f'highlight {idx}: {sample[\"highlights\"]} \\n')\n",
    "        display(f'id: {sample[\"id\"]}')\n",
    "        display('-------')\n",
    "        \n",
    "def get_samples(dataset, num_samples=10):\n",
    "    return dataset[\"train\"].shuffle(seed=1).select(range(num_samples))\n",
    "\n",
    "def get_random_sample(dataset):\n",
    "    sample = dataset[\"train\"].shuffle(seed=1).select(range(1)) \n",
    "    return [sample[\"article\"][0], sample[\"highlights\"][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb51370c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /Users/jeroen/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234/cache-17d3e0cea13717ef.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'sample 0: WASHINGTON (CNN) -- The National Transportation Safety Board began four days of hearings Tuesday on how to stem the \"drastic increase\" in medical helicopter accidents. Smoke rises from Spectrum Health Butterworth Hospital in Grand Rapids, Michigan, after a helicopter crash in May. Over a recent 12-month period, the board probed nine fatal medical helicopter accidents that killed 35 people, a development that one board member called \"alarming.\" Medical helicopters \"provide an important service to the public\" in swiftly transporting ill and injured patients and donor organs, the board said on its Web site. Chopper pilots must operate \"safely and quickly\" in bad weather, at night or on \"unfamiliar landing sites,\" the board added. \"This hearing will be extremely important because it can provide an opportunity to learn more about the industry so that possibly we can make further recommendations that can prevent these accidents and save lives,\" said Robert Sumwalt, chairman of the hearing\\'s board of inquiry.  Watch Sumwalt\\'s remarks at hearing » . Flying at night in poor weather conditions likely contributed to the crashes in Texas and Alaska of three medical helicopters that killed 11 people, the NTSB said. The three crashes occurred near South Padre Island, Texas, in February 2008; Huntsville, Texas, in June; and Whittier, Alaska, in December 2007. iReport: Watch smoke pour from a medical chopper crash in Michigan . A December 2007 accident in Cherokee, Alabama, was likely caused by the pilot flying too low over trees, the NTSB said. The helicopter was shining a searchlight on a hunter who had been lost as rescue personnel on the ground tried to reach him. The pilot, a paramedic and a flight nurse were killed, the NTSB said. Among the issues to be discussed at the hearing will be flight operations, aircraft safety equipment, training and oversight. Expert witnesses such as pilots, medical personnel, managers and Federal Aviation Administration officials will give sworn testimony on what has been an \"ongoing concern\" of the safety board, which issued a report on emergency medical services operations in 2006. The NTSB said there were 55 EMS-related aviation accidents -- both fatal and nonfatal -- between January 2002 and January 2005 that could have been prevented with \"simple corrective actions.\" In those crashes, 54 people were killed, and 18 were seriously injured, the NTSB said. The agency recommended to the FAA in January 2006 that all medical chopper operators be required to develop and implement risk evaluation programs, use dispatch and flight procedures that include up-to-date weather information, and install \"terrain awareness and warning systems\" on their aircraft. A fourth recommendation would require medical flight operators to follow federal regulations regarding their flights. The recommendations have not been fully implemented, the NTSB said. \\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'highlight 0: Transportation safety board beginning four days of hearings .\\nBoard examines reported \"drastic increase\" in accidents and deaths .\\nNine air ambulance crashes killed 35 people during one-year period .\\nBoard\\'s 2006 safety recommendations not fully implemented, it says . \\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'id: 4929e54ae3f6711b4bd8da27a46d0f8a90c3b3bf'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'-------'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_examples(raw_dataset, 1, 23)\n",
    "# get_random_sample(raw_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5486444e",
   "metadata": {},
   "source": [
    "### Model description\n",
    "BART is a transformer encoder-encoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. BART is pre-trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text.\n",
    "\n",
    "BART is particularly effective when fine-tuned for text generation (e.g. summarization, translation) but also works well for comprehension tasks (e.g. text classification, question answering)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "898a49e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# A text-to-text transformer from Google\n",
    "# https://ai.googleblog.com/2020/02/exploring-transfer-learning-with-t5.html\n",
    "pretrained_model_name = \"t5-small\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81ce50e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /Users/jeroen/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234/cache-d65aa25a11484207.arrow\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (798 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁The', '▁daughter', '▁of', '▁football', '▁legend', '▁Colin', '▁He', 'n', 'dry', '▁has', '▁spoken', '▁of', '▁her', '▁disgust', '▁at', '▁the', '▁Government', '’', 's', '▁failure', '▁to', '▁regulate', '▁cosmetic', '▁surgeon', 's', '▁', '–', '▁more', '▁than', '▁', 'a', '▁decade', '▁after', '▁her', '▁mother', '▁suffered', '▁bot', 'ched', '▁lip', 'o', 's', 'u', 'ction', '▁that', '▁led', '▁to', '▁her', '▁death', '.', '▁Den', 'is', 'e', '▁He', 'n', 'dry', '▁died', '▁in', '▁2009', '▁aged', '▁42', '▁from', '▁an', '▁infection', '▁she', '▁caught', '▁during', '▁surgery', '▁to', '▁rebuild', '▁her', '▁stomach', '.', '▁She', '▁had', '▁been', '▁in', '▁and', '▁out', '▁of', '▁hospital', '▁for', '▁seven', '▁years', '▁after', '▁', 'a', '▁plastic', '▁surgeon', '▁punct', 'ure', 'd', '▁her', '▁', 'bowel', '▁nine', '▁times', '▁in', '▁', 'a', '▁routine', '▁lip', 'o', 's', 'u', 'ction', '▁operation', '▁in', '▁2002', '.', '▁An', 'gu', 'ish', ':', '▁Colin', '▁and', '▁Den', 'is', 'e', '▁He', 'n', 'dry', '▁with', '▁R', 'he', 'a', 'gan', '▁and', '▁her', '▁brother', '▁Kyle', '▁before', '▁Den', 'is', 'e', \"'\", 's', '▁operation', '▁', '.', '▁On', 'going', '▁battle', ':', '▁R', 'he', 'a', 'gan', '▁He', 'n', 'dry', ',', '▁', 'pictured', '▁with', '▁her', '▁daughter', '▁River', ',', '▁2,', '▁is', '▁campaign', 'ing', '▁for', '▁better', '▁regulations', '▁after', '▁her', '▁mother', '▁Den', 'is', 'e', '▁died', '▁of', '▁', 'a', '▁bot', 'ched', '▁lip', 'o', 's', 'u', 'ction', '▁operation', '▁', '.', '▁Now', '▁her', '▁daughter', '▁R', 'he', 'a', 'gan', '▁He', 'n', 'dry', '▁is', '▁', 'launching', '▁', 'a', '▁new', '▁Mail', '▁on', '▁Sunday', '▁campaign', '▁under', '▁the', '▁banner', '▁Stop', '▁The', '▁Cosmetic', '▁Surgery', '▁Cow', 'boy', 's', '.', '▁R', 'he', 'a', 'gan', ',', '▁who', '▁lives', '▁with', '▁her', '▁two', '-', 'year', '-', 'old', '▁daughter', '▁River', '▁in', '▁Ly', 't', 'ham', '▁St', '▁Anne', 's', ',', '▁Lan', 'ca', 'shire', ',', '▁was', '▁just', '▁12', '▁when', '▁her', '▁mother', '▁became', '▁', 'ill', '.', '▁In', '▁her', '▁first', '▁major', '▁interview', '▁since', '▁her', '▁mother', '▁died', ',', '▁R', 'he', 'a', 'gan', ',', '▁23,', '▁says', '▁clinic', '▁owners', '▁‘', 'ans', 'wer', '▁to', '▁no', '▁one', '’', '▁and', '▁surgery', '▁is', '▁becoming', '▁ever', '▁more', '▁dangerous', '.', '▁She', '▁is', '▁shocked', '▁that', '▁repeated', '▁warning', 's', '▁from', '▁senior', '▁medic', 's', ',', '▁including', '▁', 'a', '▁former', '▁chief', '▁medical', '▁officer', ',', '▁have', '▁been', '▁ignored', '▁by', '▁Minister', 's', '.', '▁‘', 'How', '▁many', '▁more', '▁women', '▁need', '▁to', '▁die', '▁or', '▁be', '▁dis', 'figured', '▁before', '▁someone', '▁takes', '▁action', '?', '’', '▁said', '▁R', 'he', 'a', 'gan', ',', '▁', 'a', '▁care', 'r', '▁in', '▁', 'a', '▁home', '▁for', '▁the', '▁elderly', '.', '▁‘', 'My', '▁mother', '▁cannot', '▁have', '▁died', '▁in', '▁va', 'in', '.', '’', '▁Under', '▁current', '▁rules', ',', '▁doctors', '▁who', '▁perform', '▁cosmetic', '▁operations', '▁are', '▁not', '▁required', '▁to', '▁have', '▁any', '▁training', '▁in', '▁the', '▁procedures', '▁or', '▁even', '▁to', '▁be', '▁', 'a', '▁surgeon', '.', '▁Foreign', '▁doctors', '▁are', '▁', 'able', '▁to', '▁fly', '▁in', ',', '▁carry', '▁out', '▁operations', '▁and', '▁fly', '▁out', '▁without', '▁proper', '▁insurance', '▁or', '▁specialist', '▁training', '.', '▁The', '▁Mail', '▁on', '▁Sunday', '▁has', '▁', 'consulted', '▁with', '▁leading', '▁medical', '▁organisations', '▁and', '▁', 'compiled', '▁', 'a', '▁five', '-', 'point', '▁action', '▁plan', '▁to', '▁ensure', '▁patients', '▁are', '▁protected', '▁from', '▁the', '▁cow', 'boy', 's', '.', '▁We', '▁are', '▁demanding', '▁that', ':', '▁', '.', '▁Fat', 'al', '▁infection', ':', '▁Den', 'is', 'e', '▁He', 'n', 'dry', '▁with', '▁her', '▁former', '▁football', 'er', '▁Colin', '▁He', 'n', 'dry', '.', '▁Den', 'is', 'e', '▁died', '▁in', '▁2009', '▁', '.', '▁Former', '▁chief', '▁medical', '▁officer', '▁Sir', '▁Li', 'am', '▁Donald', 'son', ',', '▁now', '▁', 'a', '▁professor', '▁at', '▁Imperial', '▁College', '▁London', ',', '▁first', '▁called', '▁for', '▁tough', 'er', '▁regulations', '▁in', '▁2006.', '▁Last', '▁night', '▁', 'he', '▁said', ':', '▁‘', 'I', '▁comme', 'nd', '▁The', '▁Mail', '▁on', '▁Sunday', '▁on', '▁its', '▁campaign', '▁to', '▁protect', '▁patients', '▁from', '▁poor', '▁standards', '▁of', '▁cosmetic', '▁treatment', '.', '’', '▁Former', '▁Health', '▁Secretary', '▁Stephen', '▁Do', 'rrell', '▁said', ':', '▁‘', 'This', '▁campaign', '▁has', '▁the', '▁right', '▁objectives', '▁and', '▁something', '▁needs', '▁to', '▁be', '▁done', '.', '▁I', '▁absolutely', '▁agree', '▁that', '▁anyone', '▁carrying', '▁out', '▁cosmetic', '▁training', '▁must', '▁be', '▁properly', '▁trained', '.', '’', '▁Mr', '▁Do', 'rrell', '▁added', '▁that', '▁current', '▁regulator', 's', '▁needed', '▁to', '▁play', '▁', 'a', '▁tough', 'er', '▁role', '.', '▁Ann', '▁Cl', 'w', 'y', 'd', '▁MP', '▁was', '▁appointed', '▁by', '▁the', '▁Prime', '▁Minister', '▁as', '▁an', '▁adviser', '▁on', '▁patient', '▁complaints', '▁and', '▁has', '▁recently', '▁launched', '▁', 'a', '▁private', '▁members', '’', '▁Bill', ',', '▁The', '▁Cosmetic', '▁Surgery', '▁Bill', ',', '▁to', '▁try', '▁to', '▁tackle', '▁the', '▁issue', '.', '▁She', '▁said', ':', '▁‘', 'I', '▁am', '▁absolutely', '▁delighted', '▁by', '▁The', '▁Mail', '▁on', '▁Sunday', '▁campaign', '▁and', '▁I', '▁fully', '▁support', '▁it', '.', '’', '▁In', '▁recent', '▁years', ',', '▁the', '▁number', '▁of', '▁people', '▁opt', 'ing', '▁for', '▁cosmetic', '▁surgery', ',', '▁including', '▁nose', '▁jobs', ',', '▁breast', '▁', 'en', 'largement', 's', '▁and', '▁lip', 'o', 's', 'u', 'ction', ',', '▁has', '▁spiral', 'led', '.', '▁The', '▁Royal', '▁College', '▁of', '▁S', 'urgeon', 's', '▁estimates', '▁that', '▁last', '▁year', '▁alone', '▁1', '30,000', '▁operations', '▁were', '▁carried', '▁out', ',', '▁up', '▁five', '▁per', '▁cent', '▁on', '▁the', '▁previous', '▁year', '.', '▁Although', '▁many', '▁surgeon', 's', '▁undergo', '▁extra', '▁training', '▁to', '▁ensure', '▁they', '▁know', '▁how', '▁to', '▁do', '▁cosmetic', '▁procedures', '▁properly', ',', '▁this', '▁is', '▁not', '▁required', '▁by', '▁law', '▁', '–', '▁and', '▁in', '▁many', '▁cases', ',', '▁doctors', '▁are', '▁not', '▁skilled', '▁in', '▁the', '▁procedures', '▁they', '▁offer', '.', '▁Last', '▁year', '▁the', '▁Government', '▁ordered', '▁', 'a', '▁review', '▁of', '▁cosmetic', '▁surgery', '▁following', '▁the', '▁P', 'IP', '▁breast', '▁implant', '▁scandal', '.', '▁The', '▁report', '▁by', '▁the', '▁Department', '▁of', '▁Health', '’', 's', '▁medical', '▁director', ',', '▁Professor', '▁Sir', '▁Bruce', '▁Ke', 'o', 'g', 'h', ',', '▁is', '▁due', '▁to', '▁be', '▁published', '▁shortly', '.']\n"
     ]
    }
   ],
   "source": [
    "article, highlight = get_random_sample(raw_dataset)\n",
    "print(tokenizer.tokenize(article))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22b998c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Metric(name: \"rouge\", features: {'predictions': Value(dtype='string', id='sequence'), 'references': Value(dtype='string', id='sequence')}, usage: \"\"\"\n",
       "Calculates average rouge scores for a list of hypotheses and references\n",
       "Args:\n",
       "    predictions: list of predictions to score. Each predictions\n",
       "        should be a string with tokens separated by spaces.\n",
       "    references: list of reference for each prediction. Each\n",
       "        reference should be a string with tokens separated by spaces.\n",
       "    rouge_types: A list of rouge types to calculate.\n",
       "        Valid names:\n",
       "        `\"rouge{n}\"` (e.g. `\"rouge1\"`, `\"rouge2\"`) where: {n} is the n-gram based scoring,\n",
       "        `\"rougeL\"`: Longest common subsequence based scoring.\n",
       "        `\"rougeLSum\"`: rougeLsum splits text using `\"\n",
       "\"`.\n",
       "        See details in https://github.com/huggingface/datasets/issues/617\n",
       "    use_stemmer: Bool indicating whether Porter stemmer should be used to strip word suffixes.\n",
       "    use_agregator: Return aggregates if this is set to True\n",
       "Returns:\n",
       "    rouge1: rouge_1 (precision, recall, f1),\n",
       "    rouge2: rouge_2 (precision, recall, f1),\n",
       "    rougeL: rouge_l (precision, recall, f1),\n",
       "    rougeLsum: rouge_lsum (precision, recall, f1)\n",
       "Examples:\n",
       "\n",
       "    >>> rouge = datasets.load_metric('rouge')\n",
       "    >>> predictions = [\"hello there\", \"general kenobi\"]\n",
       "    >>> references = [\"hello there\", \"general kenobi\"]\n",
       "    >>> results = rouge.compute(predictions=predictions, references=references)\n",
       "    >>> print(list(results.keys()))\n",
       "    ['rouge1', 'rouge2', 'rougeL', 'rougeLsum']\n",
       "    >>> print(results[\"rouge1\"])\n",
       "    AggregateScore(low=Score(precision=1.0, recall=1.0, fmeasure=1.0), mid=Score(precision=1.0, recall=1.0, fmeasure=1.0), high=Score(precision=1.0, recall=1.0, fmeasure=1.0))\n",
       "    >>> print(results[\"rouge1\"].mid.fmeasure)\n",
       "    1.0\n",
       "\"\"\", stored examples: 0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric = load_metric(\"rouge\")\n",
    "metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eae5124f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input_length = 1024\n",
    "max_target_length = 128\n",
    "\n",
    "prefix = \"summarize: \"\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [prefix + doc for doc in examples[\"article\"]]\n",
    "    \n",
    "    model_inputs = tokenizer(examples[\"article\"], max_length=max_input_length, truncation=True)\n",
    "    \n",
    "    # Set up the tokenizer for targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(examples[\"highlights\"], max_length=max_target_length, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a763272d",
   "metadata": {},
   "source": [
    "Use 🤗 Datasets map function to apply the preprocessing function over the entire dataset. You can speed up the map function by setting batched=True to process multiple elements of the dataset at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37646611",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 288/288 [02:51<00:00,  1.68ba/s]\n",
      "100%|███████████████████████████████████████████| 14/14 [00:07<00:00,  1.81ba/s]\n",
      "100%|███████████████████████████████████████████| 12/12 [00:06<00:00,  1.80ba/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_cnn_dailymail = raw_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17075b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModelForSeq2SeqLM, DataCollatorForSeq2Seq\n",
    "\n",
    "model = TFAutoModelForSeq2SeqLM.from_pretrained(pretrained_model_name)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd49f234",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "learning_rate = 2e-5\n",
    "weight_decay = 0.01\n",
    "num_train_epochs = 1\n",
    "\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "push_to_hub_model_id = f\"{model_name}-finetuned-xsum\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP-summarization",
   "language": "python",
   "name": "nlp-summarization"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
