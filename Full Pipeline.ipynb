{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29c76e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/NLP-summarization/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "import transformers\n",
    "import rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd634532",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset cnn_dailymail (/Users/jeroen/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234)\n",
      "Reusing dataset cnn_dailymail (/Users/jeroen/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234)\n"
     ]
    }
   ],
   "source": [
    "raw_train_data = datasets.load_dataset(\"cnn_dailymail\", \"3.0.0\", split=\"train\")\n",
    "raw_validation_data = datasets.load_dataset(\"cnn_dailymail\", \"3.0.0\", split=\"validation[:10%]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcb436c",
   "metadata": {},
   "source": [
    "### Sample of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c885edcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_examples(dataset, num_samples=3, seed=42):\n",
    "    samples = dataset.shuffle(seed=seed).select(range(num_samples))\n",
    "        \n",
    "    for idx, sample in enumerate(samples):\n",
    "        display(f'sample {idx}: {sample[\"article\"]} \\n')\n",
    "        display(f'highlight {idx}: {sample[\"highlights\"]} \\n')\n",
    "        display(f'id: {sample[\"id\"]}')\n",
    "        display('-------')\n",
    "        \n",
    "def get_samples(dataset, num_samples=10):\n",
    "    return dataset.shuffle(seed=1).select(range(num_samples))\n",
    "\n",
    "def get_random_sample(dataset):\n",
    "    sample = dataset.shuffle(seed=1).select(range(1)) \n",
    "    return [sample[\"article\"][0], sample[\"highlights\"][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e27d49bc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /Users/jeroen/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234/cache-d65aa25a11484207.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"The daughter of football legend Colin Hendry has spoken of her disgust at the Government’s failure to regulate cosmetic surgeons – more than a decade after her mother suffered botched liposuction that led to her death. Denise Hendry died in 2009 aged 42 from an infection she caught during surgery to rebuild her stomach. She had been in and out of hospital for seven years after a plastic surgeon punctured her bowel nine times in a routine liposuction operation in 2002. Anguish: Colin and Denise Hendry with Rheagan and her brother Kyle before Denise's operation . Ongoing battle: Rheagan Hendry, pictured with her daughter River, 2, is campaigning for better regulations after her mother Denise died of a botched liposuction operation . Now her daughter Rheagan Hendry is launching a new Mail on Sunday campaign under the banner Stop The Cosmetic Surgery Cowboys. Rheagan, who lives with her two-year-old daughter River in Lytham St Annes, Lancashire, was just 12 when her mother became ill. In her first major interview since her mother died, Rheagan, 23, says clinic owners ‘answer to no one’ and surgery is becoming ever more dangerous. She is shocked that repeated warnings from senior medics, including a former chief medical officer, have been ignored by Ministers. ‘How many more women need to die or be disfigured before someone takes action?’ said Rheagan, a carer in a home for the elderly. ‘My mother cannot have died in vain.’ Under current rules, doctors who perform cosmetic operations are not required to have any training in the procedures or even to be a surgeon. Foreign doctors are able to fly in, carry out operations and fly out\\xa0 without proper insurance or specialist training. The Mail on Sunday has consulted with leading medical organisations and compiled a five-point action plan to ensure patients are protected from the cowboys. We are demanding that: . Fatal infection: Denise Hendry with her former footballer Colin Hendry. Denise died in 2009 . Former chief medical officer Sir Liam Donaldson, now a professor at Imperial College London, first called for tougher regulations in 2006. Last night he said: ‘I commend The Mail on Sunday on its campaign to protect patients from poor standards of cosmetic treatment.’ Former Health Secretary Stephen Dorrell said: ‘This campaign has\\xa0 the right objectives and something needs to be done. I absolutely agree that anyone carrying out cosmetic training must be properly trained.’ Mr Dorrell added that current regulators needed to play a tougher role. Ann Clwyd MP was appointed by the Prime Minister as an adviser on patient complaints and has recently launched a private members’ Bill, The Cosmetic Surgery Bill, to try to tackle the issue. She said: ‘I am absolutely delighted by The Mail on Sunday campaign and I fully support it.’ In recent years, the number of people opting for cosmetic surgery, including nose jobs, breast enlargements and liposuction, has spiralled. The Royal College of Surgeons estimates that last year alone 130,000 operations were carried out, up five per cent on the previous year. Although many surgeons undergo extra training to ensure they know how to do cosmetic procedures properly, this is not required by law – and in many cases, doctors are not skilled in the procedures they offer. Last year the Government ordered a review of cosmetic surgery\\xa0 following the PIP breast implant scandal. The report by the Department of Health’s medical director, Professor Sir Bruce Keogh, is due to be published shortly.\",\n",
       " 'Denise Hendry was ill for seven years after her botched liposuction .\\nShe eventually died in 2009 from an infection .\\nHer daughter Rheagan Hendry is campaigning for better regulation .\\nRheagan says that clinic owners ‘answer to no one’\\nDoctors must be properly trained in the procedures they undertake.\\nA regulatory body be established to register all cosmetic surgeons.\\nPatients should receive a 30-minute pre-surgery\\xa0 consultation and two-week cooling-off period.\\nHard-sell advertising is banned.\\nBotox professionals be registered with the regulator.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_random_sample(raw_train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc604b3",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78d01423",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /Users/jeroen/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /Users/jeroen/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /Users/jeroen/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /Users/jeroen/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /Users/jeroen/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "100%|████████████████████████████████████████████| 8/8 [00:00<00:00, 203.48ba/s]\n",
      "100%|████████████████████████████████████████████| 4/4 [00:00<00:00, 242.70ba/s]\n"
     ]
    }
   ],
   "source": [
    "batch_size=4  # change to 16 for full training\n",
    "encoder_max_length=512\n",
    "decoder_max_length=128\n",
    "\n",
    "\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def tokenize_data_to_model_input(batch):\n",
    "    inputs  = tokenizer(batch[\"article\"], padding=\"max_length\", \n",
    "                       truncation=True, max_length=encoder_max_length)\n",
    "    outputs = tokenizer(batch[\"highlights\"], padding=\"max_length\", \n",
    "                        truncation=True, max_length=decoder_max_length)\n",
    "    \n",
    "    batch[\"input_ids\"] = inputs.input_ids\n",
    "    batch[\"attention_mask\"] = inputs.attention_mask\n",
    "    batch[\"decoder_input_ids\"] = outputs.input_ids\n",
    "    batch[\"decoder_attention_mask\"] = outputs.attention_mask\n",
    "    batch[\"labels\"] = outputs.input_ids.copy()\n",
    "    \n",
    "    # because BERT automatically shifts the labels, the labels correspond exactly to `decoder_input_ids`. \n",
    "    # We have to make sure that the PAD token is ignored\n",
    "    # batch[\"labels\"] = [[-100 if token == tokenizer.pad_token_id else token for token in labels] for labels in batch[\"labels\"]]\n",
    "    \n",
    "    return batch\n",
    "\n",
    "# For now subsample is being used\n",
    "raw_train_data = raw_train_data.select(range(32))\n",
    "\n",
    "train_data = raw_train_data.map(\n",
    "    tokenize_data_to_model_input, \n",
    "    batched=True, \n",
    "    batch_size=batch_size, \n",
    "    remove_columns=[\"article\", \"highlights\", \"id\"]\n",
    ")\n",
    "train_data.set_format(\n",
    "    type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"decoder_input_ids\", \"decoder_attention_mask\", \"labels\"],\n",
    ")\n",
    "\n",
    "\n",
    "# only use 16 training examples for notebook - DELETE LINE FOR FULL TRAINING\n",
    "raw_validation_data = raw_validation_data.select(range(16))\n",
    "\n",
    "val_data = raw_validation_data.map(\n",
    "    tokenize_data_to_model_input, \n",
    "    batched=True, \n",
    "    batch_size=batch_size, \n",
    "    remove_columns=[\"article\", \"highlights\", \"id\"]\n",
    ")\n",
    "val_data.set_format(\n",
    "    type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"decoder_input_ids\", \"decoder_attention_mask\", \"labels\"],\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61ee4e0",
   "metadata": {},
   "source": [
    "### Encoder - Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0fc13f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertLMHeadModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertLMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertLMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertLMHeadModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.encoder.layer.8.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.9.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.self.query.bias', 'bert.encoder.layer.3.crossattention.output.dense.bias', 'bert.encoder.layer.5.crossattention.output.dense.weight', 'bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.11.crossattention.self.value.bias', 'bert.encoder.layer.11.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.output.dense.bias', 'bert.encoder.layer.4.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.output.dense.weight', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.self.value.weight', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.6.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.9.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.self.value.weight', 'bert.encoder.layer.5.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.8.crossattention.self.key.weight', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.self.value.weight', 'bert.encoder.layer.8.crossattention.output.dense.bias', 'bert.encoder.layer.9.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.7.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.9.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.output.dense.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.output.dense.weight', 'bert.encoder.layer.7.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.5.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.11.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.self.query.bias', 'bert.encoder.layer.8.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.11.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.3.crossattention.self.value.bias', 'bert.encoder.layer.5.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.9.crossattention.self.value.bias', 'bert.encoder.layer.10.crossattention.self.key.bias', 'bert.encoder.layer.10.crossattention.self.query.weight', 'bert.encoder.layer.3.crossattention.self.query.weight', 'bert.encoder.layer.3.crossattention.self.key.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.5.crossattention.self.value.bias', 'bert.encoder.layer.4.crossattention.output.dense.bias', 'bert.encoder.layer.10.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.8.crossattention.self.value.weight', 'bert.encoder.layer.3.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.10.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.11.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.5.crossattention.self.key.weight', 'bert.encoder.layer.11.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.self.value.bias', 'bert.encoder.layer.10.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.self.query.bias', 'bert.encoder.layer.11.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.10.crossattention.self.key.weight', 'bert.encoder.layer.7.crossattention.self.value.bias', 'bert.encoder.layer.7.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.3.crossattention.self.key.weight', 'bert.encoder.layer.7.crossattention.self.key.bias', 'bert.encoder.layer.7.crossattention.output.dense.bias', 'bert.encoder.layer.5.crossattention.self.key.bias', 'bert.encoder.layer.9.crossattention.self.value.weight', 'bert.encoder.layer.7.crossattention.self.value.weight', 'bert.encoder.layer.4.crossattention.output.dense.weight', 'bert.encoder.layer.8.crossattention.self.value.bias', 'bert.encoder.layer.4.crossattention.self.query.bias', 'bert.encoder.layer.6.crossattention.self.key.bias', 'bert.encoder.layer.5.crossattention.self.value.weight', 'bert.encoder.layer.5.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.8.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.11.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.3.crossattention.output.dense.weight', 'bert.encoder.layer.3.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.self.value.weight', 'bert.encoder.layer.9.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.3.crossattention.self.value.weight', 'bert.encoder.layer.7.crossattention.self.key.weight', 'bert.encoder.layer.4.crossattention.self.key.bias', 'bert.encoder.layer.10.crossattention.output.dense.bias', 'bert.encoder.layer.9.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.self.key.weight', 'bert.encoder.layer.4.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.9.crossattention.self.key.bias', 'bert.encoder.layer.4.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.self.query.weight', 'bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.9.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.11.crossattention.output.dense.bias', 'bert.encoder.layer.3.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.11.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.8.crossattention.output.LayerNorm.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "bert2bert = transformers.EncoderDecoderModel.from_encoder_decoder_pretrained(\"bert-base-uncased\", \"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bd2483c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set special tokens\n",
    "bert2bert.config.decoder_start_token_id = tokenizer.bos_token_id\n",
    "bert2bert.config.eos_token_id = tokenizer.eos_token_id\n",
    "bert2bert.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "# sensible parameters for beam search\n",
    "bert2bert.config.vocab_size = bert2bert.config.decoder.vocab_size\n",
    "bert2bert.config.max_length = 142\n",
    "bert2bert.config.min_length = 56\n",
    "bert2bert.config.no_repeat_ngram_size = 3\n",
    "bert2bert.config.early_stopping = True\n",
    "bert2bert.config.length_penalty = 2.0\n",
    "bert2bert.config.num_beams = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7ee4b3",
   "metadata": {},
   "source": [
    "### Evaluation Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14e928b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import Rouge \n",
    "\n",
    "rouge_scorer = Rouge()\n",
    "\n",
    "def compute_evaluation_metric(prediction):\n",
    "    labels_ids = pred.label_ids\n",
    "    pred_ids = pred.predictions\n",
    "\n",
    "    # all unnecessary tokens are removed\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n",
    "    label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
    "    \n",
    "    score = rouge_scorer.get_scores(label_str, pred_str)\n",
    "    score = round(score, 4)\n",
    "    \n",
    "    return {\n",
    "        \"rouge2_fmeasure\": score[0][\"rouge-2\"][\"f\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135b7f76",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44eeb034",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Instance and class checks can only be used with @runtime_checkable protocols",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m training_args \u001b[38;5;241m=\u001b[39m Seq2SeqTrainingArguments(\n\u001b[1;32m      6\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m     evaluation_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m#     fp16=True, \u001b[39;00m\n\u001b[1;32m     21\u001b[0m )\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# instantiate trainer\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mSeq2SeqTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbert2bert\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_evaluation_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/NLP-summarization/lib/python3.10/site-packages/transformers/trainer.py:437\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m train_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_length(train_dataset) \u001b[38;5;129;01mand\u001b[39;00m args\u001b[38;5;241m.\u001b[39mmax_steps \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_dataset does not implement __len__, max_steps has to be specified\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    436\u001b[0m     train_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 437\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIterableDataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m args\u001b[38;5;241m.\u001b[39mgroup_by_length\n\u001b[1;32m    439\u001b[0m ):\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe `--group_by_length` option is only available for `Dataset`, not `IterableDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signature_columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/NLP-summarization/lib/python3.10/typing.py:1476\u001b[0m, in \u001b[0;36m_ProtocolMeta.__instancecheck__\u001b[0;34m(cls, instance)\u001b[0m\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__instancecheck__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, instance):\n\u001b[1;32m   1469\u001b[0m     \u001b[38;5;66;03m# We need this method for situations where attributes are\u001b[39;00m\n\u001b[1;32m   1470\u001b[0m     \u001b[38;5;66;03m# assigned in __init__.\u001b[39;00m\n\u001b[1;32m   1471\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1472\u001b[0m         \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_is_protocol\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m   1473\u001b[0m         \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_is_runtime_protocol\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m   1474\u001b[0m         \u001b[38;5;129;01mnot\u001b[39;00m _allow_reckless_class_checks(depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m   1475\u001b[0m     ):\n\u001b[0;32m-> 1476\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInstance and class checks can only be used with\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1477\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m @runtime_checkable protocols\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1479\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_is_protocol\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1480\u001b[0m             _is_callable_members_only(\u001b[38;5;28mcls\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m   1481\u001b[0m             \u001b[38;5;28missubclass\u001b[39m(instance\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, \u001b[38;5;28mcls\u001b[39m)):\n\u001b[1;32m   1482\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: Instance and class checks can only be used with @runtime_checkable protocols"
     ]
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "learning_rate=2e-5\n",
    "weight_decay = 0.01\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=learning_rate,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    predict_with_generate=True,\n",
    "    weight_decay=weight_decay,\n",
    "    logging_steps=2,  # set to 1000 for full training\n",
    "    save_steps=16,  # set to 500 for full training\n",
    "    eval_steps=4,  # set to 8000 for full training\n",
    "    warmup_steps=1,  # set to 2000 for full training\n",
    "    max_steps=16, # delete for full training\n",
    "    overwrite_output_dir=True,\n",
    "    save_total_limit=3,\n",
    "#     fp16=True, \n",
    ")\n",
    "\n",
    "# instantiate trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=bert2bert,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_evaluation_metric,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=val_data,\n",
    ")\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP-summarization",
   "language": "python",
   "name": "nlp-summarization"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
